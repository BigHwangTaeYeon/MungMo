[kafka 데이터베이스 동기화](#kafka)
[스케쥴러 vs 쿼츠](#scheduler-vs-quartz)
[채팅 서버](#채팅-서버)

### kafka

Kafka 사용 이유, EDA(Event-Driven Architecture)
핵심 비동기, 분산처리

서비스 간의 통신
기존에는 RestApi 통신으로, 커플링되어 응답 서버에 문제가 있으면 요청한 서버에서 진행이 안되기에 디커플링이 필요하다.
(MSA 의 의존성 낮추는 장점이 무너짐)
I/O 데이터 구조 변경이 어려움
(연결되는 서비스가 모두 다 같이 변경 해야한다.)
부하분산 필요
메시지 큐(Rabbit MQ, Active MQ)
메모리에서 관리하고 반환하면 기존 데이터를 삭제한다.(여러 서비스에 전송 불가)
낮은 처리량(through put)
높은 레이턴시(latency)
그래서 이벤트 기반 MSA 아키텍쳐 Apache kafka 사용

rest api vs kafka cdc
핵심 데이터 정합성
REST API 호출이 적합한 경우:
실시간 데이터 접근이 필요할 때
동기적 처리와 강한 일관성이 필요할 때
이벤트 기반 통신이 적합한 경우:
비동기적 처리가 가능하고 일관성 요구가 낮을 때
서비스 간의 결합도를 낮추고 확장성을 높이고 싶을 때

ZooKeeper Cluster 기본 구성
ZooKeeper Service 는 “Ensemble” 이라고 불리는 Host 들의 집합들을 통해서 복제되며,
동일한 어플리케이션을 구성하는 서버들의 복제된 그룹을 “Quorum” 이라고 부른다.
Quorum 내의 모든 서버는 동일한 설정 파일들의 복제본을 가지고 있다.
ZooKepper의 서버 구성의 수는 절반이 실패해도 기능을 수행할 수 있도록 항상 홀수로 구성하는 것을 권장한다.
예를 들어 2대의 서버가 장애 상태가 되어도 나머지 서버들이 동작할 수 있도록 5대의 서버로 구성하는 것이다.
이 중에 한 대는 Leader가 된다. 최소한의 구성은 3 대가 된다.
참조 : https://yooloo.tistory.com/102



    환경
kafka_2.13-3.7.0
connect : curl -O http://packages.confluent.io/archive/7.5/confluent-community-7.5.0.tar.gz
connector : curl -O https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-jdbc/versions/10.6.4/confluentinc-kafka-connect-jdbc-10.6.4.zip

    실행
$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
$ bin/kafka-server-start.sh -daemon config/server.properties
$ bin/connect-distributed -daemon ./etc/kafka/connect-distributed.properties


Zookeeper: 2181
Kafka Broker: 9092
Kafka Connect REST API: 8083

bin/kafka-server-stop.sh && bin/kafka-server-start.sh -daemon config/server.properties

$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
$ bin/kafka-server-start.sh -daemon config/server.properties

Zookeeper 의 기본 포트는 2181이고 Kafka 의 기본 포트는 9092
$ lsof -i :9092     (pid 확인)
$ kill -9 1523

$ bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
$ bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic HereTopicName --partitions 1
$ bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topicname --partitions 1 --replication-factor 1

$ bin/kafka-topics.sh --delete --topic HereTopicName --bootstrap-server localhost:9092
   topic 삭제를 하여면 먼저 생성한 connector 부터 삭제해야한다.
   커넥터 삭제 : DELETE http://localhost:8083/connectors/my-sink-connect-member
   토픽 삭제 : bin/kafka-topics.sh --delete --topic my_topic_test001 --bootstrap-server localhost:9092
   확인 : bin/kafka-topics.sh --bootstrap-server localhost:9092 --list

Producer 등록
$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic HereTopicName
$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topicname

Consumer 등록
$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic HereTopicName --from-beginning
$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topicname --from-beginning




connect
$ bin/connect-distributed -daemon ./etc/kafka/connect-distributed.properties
$ lsof -i :8083

mariadb-java-client-2.7.2.jar 파일을 kafka connect → share/java/kafka로 복사함

connect-distributed.properties 파일은 Apache Kafka 의 Connect 분산 모드에서 사용되는 설정 파일입니다.
```properties
plugin.path=/usr/share/java
```
위 경로를 jdbc.jar 파일 경로로 변경해야한다.
```properties
plugin.path=/Users/userName/Documents/workspace/MungMo/confluentinc-kafka-connect-jdbc-10.6.4/lib/
```



1. 토픽 생성
   {
   "name" : "test-connect-mungmo-member004",
   "config" : {
   "connector.class" : "io.confluent.connect.jdbc.JdbcSourceConnector",
   "connection.url":"jdbc:mysql://localhost:3306/mungmoMember",
   "connection.user":"mungmo",
   "connection.password":"1234",
   "mode": "incrementing",
   "incrementing.column.name" : "member_id",
   "table.whitelist":"mungmoMember.oauth_login",
   "topic.prefix" : "service_",
   "tasks.max" : "1"
   }
   }

kafka 토픽에 저장될 이름 형식 지정 위 같은경우 whitelist를 뒤에 붙여 example_topic_users에 데이터가 들어감
tasks.max : 커넥터에 대한 작업자 수

참고로 table.whitelist 에 dot 로 해당_데이터배이스.테이블_명 으로 명시해주어야 한다.

2. sink connect 생성
   {
   "name":"my-sink-connect-member003",
   "config":{
   "connector.class":"io.confluent.connect.jdbc.JdbcSinkConnector",
   "connection.url":"jdbc:mysql://localhost:3306/mungmoBoard",
   "connection.user":"mungmo",
   "connection.password":"1234",
   "auto.create":"true",
   "auto.evolve":"true",
   "delete.enabled":"false",
   "tasks.max":"1",
   "topics":"service_oauth_login"
   }
   }

auto.create : 데이터를 넣을 테이블이 누락되었을 경우 자동 테이블 생성 여부
auto.evolve : 특정 데이터의 열이 누락된 경우 대상 테이블에 ALTER 구문을 날려 자동으로 테이블 구조를 바꾸는지 여부 (하지만 데이터 타입 변경, 컬럼 제거, 키본 키 제약 조건 추가등은 시도되지 않는다)
delete.enabled : 삭제 모드 여부

```text
/**
* CDC 를 통한 테이블 생성 시 문제.
* 1. jpa 로 복제 테이블을 생성하면 컨슈머에서 insert 를 하지 않음
* 2. 일반적으로 개발 단계에서 jpa ddl-auto 설정을 update 로 하고 토픽을 통해 복제 테이블을 생성한 후, create 해줘야함.
* 3. 이렇게 생성하면 테이블이 내가 설계한대로 생성, 수정되지않고 뒤죽박죽이 되어 디테일 설정을 해줘야한다.
*
* 해결
* 1. 복제 테이블인 service_oauth_login의 PRIMARY KEY (member_id) 설정과 unique(town_id) 설정.
* 2. 컨슈머가 가지고 있는 메시지를 통해 복제 테이블의 데이터를 생성하여 엔티티에 설정한 alter foreign key 가 문제가 되는데,
* 		insert 된 데이터를 연관관계의 테이블에도 참조 무결성이 위배되지 않게 데이터를 입력해줘야한다.
* 		foreign key 를 가지고 있는 테이블은 자식 테이블이 되기에 부모테이블의 참조값을 무조건 가지고 있어야한다. 그러므로 not null
* 		INSERT INTO service_town  values(2,'seoul',false, '2024-07-06 03:59:13');
*/
```


3. table 또는 데이터 생성 수정 삭제
   mungMo 데이터베이스에서 dml 에 의해 mungmoMember 에 데이터 복제


connect mode 로 incrementing 를 사용한 결과, 수정을 감지못하는 상황을 확인하였다. 

kafka connect mode
bulk : 데이터를 폴링할 때 마다 전체 테이블을 복사
incrementing : 특정 컬럼의 중가분만 감지되며, 기존 행의 수정과 삭제는 감지되지 않음
timestamp : timestamp형 컬럼일 경우, 새 행과 수정된 행을 감지함

벌크는 모든 데이터 삭제, 삽입이 오버헤드로 느껴지고, 타임스탬프는 모든 테이블에 컬럼을 추가하고, 수정 시 같이 변경해줘야한다는 것이 부담이 되었다.

cdc 도구로 Debezium 를 사용하기로 하였다.


==========================================================================================

### Scheduler vs Quartz

1. 동네인증
한달에 한번 재인증을 해야한다.
유저 데이터의 인증 여부, 인증일을 확인하여 30일 이후 동네인증 취소를 해야한다.

1분 단위 작업을 ShedLock 으로 중복 실행되지 않도록 구현하였다.

스케쥴, 쿼츠 고민은 작업이 너무 간단하여 스케쥴로 결정

2. 24시 동물병원


==========================================================================================

### 채팅 서버

MQ

SQL
   NoSQL
      낮은 레이턴시
























